{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio Oficina de aprendizado de máquinas da comunidade AI Girls\n",
    "\n",
    "Grupo C: Ana Maria Bender, Klara Narumi e Larrissa Rocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn.metrics import r2_score # quanto mais proximo de 1 melhor o modelo\n",
    "from sklearn.metrics import mean_absolute_error # desvio médio entre observado e predito.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from graphviz import render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar dados\n",
    "\n",
    "df_modelo = pd.read_csv('df_modelo.csv')\n",
    "df_modelo.head()\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo arvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define as caracteristicas para treinar o modelo\n",
    "\n",
    "X = df_modelo.drop(['G3'], axis=1)\n",
    "y = df_modelo['G3']\n",
    "\n",
    "X_social=df_modelo[['activities','freetime','reason','romantic','goout','Dalc','Walc','G1','G2']]\n",
    "X_family=df_modelo[['famsize','Pstatus','Medu','Fedu','Mjob','Fjob','guardian','famsup','nursery','famrel','G1','G2']]\n",
    "X_demog=df_modelo[['school','sex','age','address','traveltime','studytime','internet','failures','absences','schoolsup','paid','health','higher','G1','G2']]\n",
    "X_correlacao=df_modelo[['age','address','traveltime','Medu','Fedu','higher','failures','G1','G2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos usar uma arvore de decisão aqui! \n",
    "\n",
    "Esse tipo de algoritmo é muito interessante, porque é fácil entender porque ele classificou uma amostra em um determinado valor. Isso porque ele funciona como se fosse feitas uma series de perguntas e então chega-se a uma conclusão.É uma estratégia conhecida como dividir para conquistar: um problema complexo é decomposto em sub-problemas mais simples e recursivamente esta técnica é aplicada a cada sub-problema \n",
    "\n",
    "Com esse tipo de algoritmo normalmente não precisamos escalar os dados, ele consegue lidar com dados que não são separados linearmente e a importância dos atributos é revelada e fácil de explicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria uma função para treinar, testar e avaliar o modelo em uma unica chamadinha (contem grafico da árvore e grafico de importancia das características) <3\n",
    "\n",
    "def arvore_test(X,y,max_depth):\n",
    "\n",
    "## treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)\n",
    "    X_test.shape\n",
    "\n",
    "# Fit regression model\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    regr_1.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "    y_pred = regr_1.predict(X_test)\n",
    "\n",
    "# export the decision tree to a tree.dot file # for visualizing the plot easily anywhere #só ta salvando um pq sempre salva com o mesmo nome...\n",
    "    export_graphviz(regr_1, out_file ='tree.dot')  \n",
    "    render('dot', 'png', 'tree.dot')\n",
    "\n",
    "# plot tree\n",
    "    plt.figure(figsize=(10,10))  # set plot size (denoted in inches)\n",
    "    tree.plot_tree(regr_1, fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "    importance = regr_1.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "        print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "    features_n = X.columns\n",
    "    features_n\n",
    "\n",
    "# plot feature importance\n",
    "    pyplot.bar([x for x in range(len(importance))], importance)\n",
    "    pyplot.xticks([x for x in range(len(importance))], features_n, rotation='vertical')\n",
    "    pyplot.show()\n",
    "         \n",
    "## Evaluation\n",
    "   \n",
    "    print('r2 score: y_test and y_predito')  \n",
    "    print(r2_score(y_test, y_pred))\n",
    "        \n",
    "    print('mean absolute error y_test e y_predito')\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    print('mean squared error y_test e y_predito')\n",
    "    print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_test(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_test(X_correlacao, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_test(X_social,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_test(X_family,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore_test(X_demog,y,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de avaliação do modelo de regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem algumas estatísticas que podemos usar para avaliar se o nosso modelo fez um bom trabalho na previsão das notas finais, as mais comuns para modelos de regressão, e que usamos nesse projeto são:\n",
    "- Erro Médio Absoluto / Mean Absolute Error (MAE):\n",
    "Aqui é calculado o resíduo, ou seja, a diferença absoluta entre o valor predito e o valor real de cada ponto, e depois é tirada uma média desses valores. O MAE descreve a magnitude típica dos resíduos, é uma métrica bastante intuitiva e quanto maior seu valor, mais o nosso modelo está \"errando\".\n",
    "- Erro Quadrado Médio / Mean Square Error (MSE):\n",
    "É parecido com o MAE, porém eleva ao quadrado a diferença entre o valor predito e o verdadeiro, então aqui  diferenças menores têm menos importância, enquanto diferenças maiores recebem mais peso.\n",
    "- R^2:\n",
    "Também conhecido como coeficiente de determinação, ele fornece uma indicação da qualidade do ajuste e, portanto, uma medida de quão bem as amostras não vistas podem ser previstas pelo modelo, por meio da proporção da variância explicada. O melhor score possível é 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notamos que os melhores resultados, foram utilizando todas as features da base de dados (X) e utilizando os dados demográficos (X_demog);\n",
    "* Já o X_family, o X_social e o X_correlacao apesar de apresentarem MAE baixo, apresentam MSE alto. É esperado que o MSE seja maior do que o MAE, porém com o R^2 se afastando do valor ideal (1), nota-se que com essa seleção de características a performance do modelo cai;\n",
    "* Uma possível causa dessa diferença entre os resultados gerados com cada conjunto de features é a quantidade de features, pois em X e X_demog temos mais características alimentando o modelo;\n",
    "* Com relação à profundidade máxima da árvore de decisão, notamos que o valor ideal é 5. Valores menores ou maiores do que 5 fazem a performance do modelo cair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
